# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2011â€“2018 <a href="http://kennethreitz.com/pages/open-projects.html">Kenneth Reitz</a> &amp; <a href="https://realpython.com">Real Python</a>. <a href="http://creativecommons.org/licenses/by-nc-sa/3.0/">CC BY-NC-SA 3.0</a>
# This file is distributed under the same license as the pythonguide package.
# FIRST AUTHOR <EMAIL@ADDRESS>, YEAR.
# 
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: pythonguide 0.0.1\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2019-02-10 18:10+0100\n"
"PO-Revision-Date: 2017-03-18 10:44+0000\n"
"Language-Team: Portuguese (Brazil) (https://www.transifex.com/own-16/teams/72945/pt_BR/)\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Language: pt_BR\n"
"Plural-Forms: nplurals=2; plural=(n > 1);\n"

#: ../../scenarios/scrape.rst:4
msgid "HTML Scraping"
msgstr ""

#: ../../scenarios/scrape.rst:11
msgid "Web Scraping"
msgstr ""

#: ../../scenarios/scrape.rst:13
msgid ""
"Web sites are written using HTML, which means that each web page is a "
"structured document. Sometimes it would be great to obtain some data from "
"them and preserve the structure while we're at it. Web sites don't always "
"provide their data in comfortable formats such as CSV or JSON."
msgstr ""

#: ../../scenarios/scrape.rst:18
msgid ""
"This is where web scraping comes in. Web scraping is the practice of using a"
" computer program to sift through a web page and gather the data that you "
"need in a format most useful to you while at the same time preserving the "
"structure of the data."
msgstr ""

#: ../../scenarios/scrape.rst:26
msgid "lxml and Requests"
msgstr ""

#: ../../scenarios/scrape.rst:28
msgid ""
"`lxml <http://lxml.de/>`_ is a pretty extensive library written for parsing "
"XML and HTML documents very quickly, even handling messed up tags in the "
"process. We will also be using the `Requests <http://docs.python-"
"requests.org/en/latest/>`_ module instead of the already built-in urllib2 "
"module due to improvements in speed and readability. You can easily install "
"both using ``pip install lxml`` and ``pip install requests``."
msgstr ""

#: ../../scenarios/scrape.rst:36
msgid "Let's start with the imports:"
msgstr ""

#: ../../scenarios/scrape.rst:43
msgid ""
"Next we will use ``requests.get`` to retrieve the web page with our data, "
"parse it using the ``html`` module, and save the results in ``tree``:"
msgstr ""

#: ../../scenarios/scrape.rst:51
msgid ""
"(We need to use ``page.content`` rather than ``page.text`` because "
"``html.fromstring`` implicitly expects ``bytes`` as input.)"
msgstr ""

#: ../../scenarios/scrape.rst:54
msgid ""
"``tree`` now contains the whole HTML file in a nice tree structure which we "
"can go over two different ways: XPath and CSSSelect. In this example, we "
"will focus on the former."
msgstr ""

#: ../../scenarios/scrape.rst:58
msgid ""
"XPath is a way of locating information in structured documents such as HTML "
"or XML documents. A good introduction to XPath is on `W3Schools "
"<http://www.w3schools.com/xml/xpath_intro.asp>`_ ."
msgstr ""

#: ../../scenarios/scrape.rst:62
msgid ""
"There are also various tools for obtaining the XPath of elements such as "
"FireBug for Firefox or the Chrome Inspector. If you're using Chrome, you can"
" right click an element, choose 'Inspect element', highlight the code, right"
" click again, and choose 'Copy XPath'."
msgstr ""

#: ../../scenarios/scrape.rst:67
msgid ""
"After a quick analysis, we see that in our page the data is contained in two"
" elements -- one is a div with title 'buyer-name' and the other is a span "
"with class 'item-price':"
msgstr ""

#: ../../scenarios/scrape.rst:76
msgid ""
"Knowing this we can create the correct XPath query and use the lxml "
"``xpath`` function like this:"
msgstr ""

#: ../../scenarios/scrape.rst:86
msgid "Let's see what we got exactly:"
msgstr ""

#: ../../scenarios/scrape.rst:106
msgid ""
"Congratulations! We have successfully scraped all the data we wanted from a "
"web page using lxml and Requests. We have it stored in memory as two lists. "
"Now we can do all sorts of cool stuff with it: we can analyze it using "
"Python or we can save it to a file and share it with the world."
msgstr ""

#: ../../scenarios/scrape.rst:111
msgid ""
"Some more cool ideas to think about are modifying this script to iterate "
"through the rest of the pages of this example dataset, or rewriting this "
"application to use threads for improved speed."
msgstr ""
